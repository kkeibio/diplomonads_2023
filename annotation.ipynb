{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "FULLNAMELINEAGE_SQLITE3 = Path('fullnamelineage.sqlite3')\n",
    "FORMAT = 'qseqid sseqid saccver evalue staxids length qlen slen pident stitle qseq sseq qcovs frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isoform_pattern = re.compile(r'(^TRINITY_DN[0-9]+_c[0-9]+_g[0-9]+_i[0-9]+)\\.p[0-9]+')\n",
    "\n",
    "def tdid2tid(tdid: str):\n",
    "    # transdecoder_id to trinity_id\n",
    "    if (res := isoform_pattern.search(tdid)) is not None:\n",
    "        return res.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_result_file = Path('./local.blast_result.tsv')\n",
    "blast_df = pd.read_csv(blast_result_file, delimiter='\\t', header=None, names=FORMAT.split(' '))\n",
    "blast_df = blast_df.astype({'qseqid': str, 'sseqid': str, 'saccver': str, 'evalue': float, 'staxids': str, 'length': int, 'qlen': int, 'slen': int, 'pident': float, 'stitle': str, 'qseq': str, 'sseq': str, 'qcovs': float, 'frames': str})\n",
    "# blast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_df['qseqid_trinity'] = [ tdid2tid(x) for x in blast_df['qseqid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_hits(df):\n",
    "    return_list = []\n",
    "    grouped = df.groupby('qseqid_trinity')\n",
    "\n",
    "    for _, group in tqdm(grouped):\n",
    "        min_evalue_rows = group[group['evalue'] == group['evalue'].min()]\n",
    "        # if len(min_evalue_rows) > 1:\n",
    "        max_b_rows = min_evalue_rows[min_evalue_rows['qcovs'] == min_evalue_rows['qcovs'].max()]\n",
    "        max_pident_rows = max_b_rows[max_b_rows['pident'] == max_b_rows['pident'].max()]\n",
    "\n",
    "        if len(max_pident_rows) > 1:\n",
    "            max_pident_rows = max_pident_rows.sample(n=1)\n",
    "        result = max_pident_rows.to_dict(orient='records')[0]\n",
    "        return_list.append(result)\n",
    "    return return_list\n",
    "\n",
    "df_list = select_best_hits(blast_df)\n",
    "blast_result_best_evalue_df = pd.DataFrame.from_records(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IPS(file) -> pd.DataFrame:\n",
    "    def process_match_and_create_annotations(match):\n",
    "        signature_db = match['signature']['signatureLibraryRelease']['library']\n",
    "        if signature_db == 'MOBIDB_LITE':\n",
    "            return []\n",
    "        if not match['signature']:\n",
    "            return []\n",
    "        entry = match['signature'].get('entry')\n",
    "        if entry is None:\n",
    "            return []\n",
    "        accession = entry[\"accession\"]\n",
    "        description = entry.get(\"description\") or match.get(\"name\") or ''\n",
    "        entry_type = entry[\"type\"]\n",
    "\n",
    "        annotation_entries = []\n",
    "        for loc in match['locations']:\n",
    "            location_str = f\"{loc['start']}-{loc['end']}\"\n",
    "            evalue_str = str(loc['evalue']) if 'evalue' in loc else ''\n",
    "            score_str = str(loc['score']) if 'score' in loc else ''\n",
    "\n",
    "            for _id in ids:\n",
    "                annotation_dict = {\n",
    "                    'id': _id,\n",
    "                    'accession': accession,\n",
    "                    'evalue': evalue_str,\n",
    "                    'score': score_str,\n",
    "                    'description': description,\n",
    "                    'type': entry_type,\n",
    "                    'location': location_str,\n",
    "                    'signature_db': signature_db,\n",
    "                }\n",
    "                annotation_entries.append(annotation_dict)\n",
    "\n",
    "        return annotation_entries\n",
    "\n",
    "    with open(file, 'r') as json_file:\n",
    "        annotation_data = json.load(json_file)\n",
    "\n",
    "    annotations = []\n",
    "    for result in annotation_data['results']:\n",
    "        ids = [x['id'] for x in result['xref']]\n",
    "\n",
    "        for match in result['matches']:\n",
    "            annotations += process_match_and_create_annotations(match)\n",
    "\n",
    "    annotation_info = pd.DataFrame(annotations).drop_duplicates()\n",
    "\n",
    "    return annotation_info\n",
    "\n",
    "\n",
    "interproscan_df = load_IPS('./interproscan_result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interproscan_df['evalue'] = interproscan_df['evalue'].apply(lambda x: float(x) if x != '' else 1e+100)\n",
    "interproscan_df['score'] = interproscan_df['score'].apply(lambda x: float(x) if x != '' else 0.0)\n",
    "interproscan_df['trinity_id'] = [ tdid2tid(x) for x in interproscan_df['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_hits_inter(df):\n",
    "    list_ = []\n",
    "    grouped = df.groupby('trinity_id')\n",
    "\n",
    "    for _, group in tqdm(grouped):\n",
    "        min_a_rows = group[group['evalue'] == group['evalue'].min()]\n",
    "        max_b_rows = min_a_rows[min_a_rows['score'] == min_a_rows['score'].max()]\n",
    "\n",
    "        if len(max_b_rows) > 1:\n",
    "            max_b_rows = max_b_rows.sample(n=1)\n",
    "        result = max_b_rows.to_dict(orient='records')[0]\n",
    "        list_.append(result)\n",
    "    return list_\n",
    "\n",
    "interproscan_best_evalue_list = select_best_hits_inter(interproscan_df)\n",
    "interproscan_best_evalue_df = pd.DataFrame.from_records(interproscan_best_evalue_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_join_df = blast_result_best_evalue_df.copy()\n",
    "blast_join_df['trinity_id'] = blast_join_df['qseqid_trinity'].copy()\n",
    "blast_join_df.drop(['qseqid_trinity', 'saccver', 'staxids', 'length', 'qlen', 'slen', 'pident', 'qcovs', 'frames'], axis=1, inplace=True)\n",
    "\n",
    "ipr_join_df = interproscan_best_evalue_df.copy()\n",
    "ipr_join_df.drop(['accession', 'location', 'signature_db'], axis=1, inplace=True)\n",
    "\n",
    "merged_df = blast_join_df.merge(ipr_join_df, on='trinity_id', how='outer', suffixes=('_blast', '_ipr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_row_based_on_evalue(row):\n",
    "    d_ = {}\n",
    "    if pd.notnull(row['evalue_blast']) and pd.notnull(row['evalue_ipr']):\n",
    "        if row['evalue_blast'] <= 1e-40:\n",
    "            d_ = {'transdecoder_id': row['qseqid'],\n",
    "                'trinity_id': row['trinity_id'],\n",
    "                'sseqid': row['sseqid'],\n",
    "                'stitle': row['stitle'],\n",
    "                'evalue': row['evalue_blast'],}\n",
    "        else:\n",
    "            d_ = {'transdecoder_id': row['id'],\n",
    "                'trinity_id': row['trinity_id'],\n",
    "                'sseqid': '',\n",
    "                'stitle': row['description'],\n",
    "                'evalue': row['evalue_ipr'],}\n",
    "    elif pd.notnull(row['evalue_blast']) and pd.isnull(row['evalue_ipr']):\n",
    "        d_ = {'transdecoder_id': row['qseqid'],\n",
    "              'trinity_id': row['trinity_id'],\n",
    "              'sseqid': row['sseqid'],\n",
    "              'stitle': row['stitle'],\n",
    "              'evalue': row['evalue_blast'],}\n",
    "    elif pd.isnull(row['evalue_blast']) and pd.notnull(row['evalue_ipr']):\n",
    "        d_ = {'transdecoder_id': row['id'],\n",
    "              'trinity_id': row['trinity_id'],\n",
    "              'sseqid': '',\n",
    "              'stitle': row['description'],\n",
    "              'evalue': row['evalue_ipr'],}\n",
    "    else:\n",
    "        raise ValueError('Unexpected value.')\n",
    "    return d_\n",
    "\n",
    "d_list = merged_df.apply(select_row_based_on_evalue, axis=1)\n",
    "selected_df = pd.DataFrame.from_records(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product name\n",
    "uniprot_pattern = re.compile(r'^sp\\|')\n",
    "uniprot_product_OS_suffix_pattern = re.compile(r'\\sOS=.*$')\n",
    "trichomonas_pattern = re.compile(r'^Trichomonas_vaginalis_G3_PRJNA16084.fasta#')\n",
    "trepomonas_pattern = re.compile(r'^Trepomonas_sp._PC1_PRJNA288252.fasta#')\n",
    "giardia_pattern = re.compile(r'^Giardia_intestinalis_PRJNA1439.fasta#')\n",
    "spironucleus_pattern = re.compile(r'^Spironucleus.salmonicida_PRJNA60811.fasta#')\n",
    "\n",
    "def processing_blast_stitle(row):\n",
    "\tdef remove_saccver_from_stitle(x) -> str:\n",
    "\t\treturn x['stitle'].replace(x['sseqid'], '').strip()\n",
    "\tdef extract_product_name(x: str) -> str:\n",
    "\t\treturn x.split(' [')[0].strip()\n",
    "\n",
    "\tif row['sseqid'] != '':  # blast\n",
    "\t\tproduct_name = remove_saccver_from_stitle(row)\n",
    "\t\tif uniprot_pattern.match(row['sseqid']):\n",
    "\t\t\tproduct_name = product_name.split(' OS=')[0]\n",
    "\t\telse:\n",
    "\t\t\tproduct_name = extract_product_name(product_name)\n",
    "\telse:  # interproscan: row['sseqid'] == ''\n",
    "\t\tproduct_name = row['stitle']\n",
    "\treturn product_name\n",
    "\n",
    "selected_df['product_name'] = selected_df.apply(processing_blast_stitle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For hypothetical proteins\n",
    "annotated_trinity_id = selected_df['trinity_id'].unique()\n",
    "\n",
    "trinity_assembly_file = Path('./Trinity.fasta')  # RNA-seq trinity, original\n",
    "with open(trinity_assembly_file) as f:\n",
    "    assemblyId2records = SeqIO.to_dict(SeqIO.parse(trinity_assembly_file, 'fasta'))\n",
    "trinity_assembly_ids = set(assemblyId2records.keys())\n",
    "unannotated_trinity_ids = trinity_assembly_ids - set(annotated_trinity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_file = Path('./longest_orf.pep')\n",
    "records = list(SeqIO.parse(pep_file, 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unannotated_trinity_id_to_unannotated_transdecoder_record = {}\n",
    "for record in records:\n",
    "    trinity_id_ = tdid2tid(record.id)\n",
    "    if trinity_id_ in unannotated_trinity_ids:\n",
    "        if unannotated_trinity_id_to_unannotated_transdecoder_record.get(trinity_id_, False):\n",
    "            unannotated_trinity_id_to_unannotated_transdecoder_record[trinity_id_].append(record)\n",
    "        else:\n",
    "            unannotated_trinity_id_to_unannotated_transdecoder_record[trinity_id_] = [record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 300\n",
    "hypo_candidates_transdecoder_ids_300aa = {}\n",
    "for key_trinity_id, values_td_records in unannotated_trinity_id_to_unannotated_transdecoder_record.items():\n",
    "\tfor record in values_td_records:\n",
    "\t\tlen_seq = len(str(record.seq))\n",
    "\t\tif len_seq >= min_length:\n",
    "\t\t\tif not hypo_candidates_transdecoder_ids_300aa.get(key_trinity_id, False):\n",
    "\t\t\t\thypo_candidates_transdecoder_ids_300aa[key_trinity_id] = record\n",
    "\t\t\telse:\n",
    "\t\t\t\tif len_seq > len(str(hypo_candidates_transdecoder_ids_300aa[key_trinity_id].seq)):\n",
    "\t\t\t\t\thypo_candidates_transdecoder_ids_300aa[key_trinity_id] = record\t\n",
    "\t\t\t\t\t# print('{} -> {}.'.format(len_seq, len(str(hypo_candidates_transdecoder_ids_300aa[key_trinity_id].seq))))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "hypo_candidates_transdecoder_ids_more_than_300 = {k: v for k, v in sorted(hypo_candidates_transdecoder_ids_300aa.items(), key=lambda item: len(str(item[1].seq)), reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = []\n",
    "for k, v in hypo_candidates_transdecoder_ids_more_than_300.items():\n",
    "\td_list.append({'transdecoder_id': v.id, 'trinity_id': k, 'product_name': 'Hypothetical protein', 'evalue': '99.9'})\n",
    "hyp_df = pd.DataFrame(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([selected_df, hyp_df], axis=0)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names_df = final_df[['transdecoder_id', 'trinity_id', 'product_name', 'evalue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names_df.to_csv('product_names.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
